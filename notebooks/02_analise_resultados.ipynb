{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# An√°lise de Resultados do Modelo\n",
    "\n",
    "Neste notebook vamos:\n",
    "1. Carregar o modelo treinado\n",
    "2. Avaliar performance no conjunto de teste\n",
    "3. Visualizar matriz de confus√£o\n",
    "4. Analisar erros comuns\n",
    "5. Visualizar curvas de aprendizado\n",
    "6. Testar em imagens espec√≠ficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milenemartins/Documents/projetos-pessoais/neuroguide/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Adicionar o diret√≥rio raiz ao path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from src.utils.config_loader import config\n",
    "from src.emotion_recognition.data_loader import EmotionDataLoader\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados e Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Modelo n√£o encontrado: /Users/milenemartins/Documents/projetos-pessoais/neuroguide/models/emotion_cnn_XXXXXX_best.h5\n",
      "\n",
      "Modelos dispon√≠veis:\n",
      "\n",
      "‚ö†Ô∏è Atualize MODEL_NAME acima com um dos modelos listados\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√µes\n",
    "paths = config.get_paths()\n",
    "emotion_classes_pt = config['dataset']['classes']\n",
    "\n",
    "# Mapear para ingl√™s (nomes nas pastas)\n",
    "emotion_classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "# ALTERE AQUI: Coloque o nome do seu modelo treinado\n",
    "MODEL_NAME = 'emotion_cnn_XXXXXX_best.h5'  # Substitua XXXXXX pelo timestamp\n",
    "\n",
    "model_path = paths['models_dir'] / MODEL_NAME\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f\"‚ùå Modelo n√£o encontrado: {model_path}\")\n",
    "    print(\"\\nModelos dispon√≠veis:\")\n",
    "    for m in sorted(paths['models_dir'].glob('*.h5')):\n",
    "        print(f\"  - {m.name}\")\n",
    "    print(\"\\n‚ö†Ô∏è Atualize MODEL_NAME acima com um dos modelos listados\")\n",
    "else:\n",
    "    print(f\"‚úÖ Carregando modelo: {model_path.name}\")\n",
    "    model = load_model(model_path)\n",
    "    print(\"‚úì Modelo carregado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados de teste...\n",
      "Found 7178 images belonging to 7 classes.\n",
      "\n",
      "‚úì Dados de teste carregados:\n",
      "  Total de amostras: 7178\n",
      "  Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados de teste usando generator\n",
    "print(\"Carregando dados de teste...\")\n",
    "\n",
    "data_loader = EmotionDataLoader(\n",
    "    data_path=paths['data_dir'],\n",
    "    img_size=tuple(config['dataset']['img_size']),\n",
    "    num_classes=config['dataset']['num_classes'],\n",
    "    color_mode=config['dataset']['color_mode']\n",
    ")\n",
    "\n",
    "# Criar apenas test generator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    str(paths['data_dir'] / 'test'),\n",
    "    target_size=tuple(config['dataset']['img_size']),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Importante para an√°lise\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Dados de teste carregados:\")\n",
    "print(f\"  Total de amostras: {test_generator.samples}\")\n",
    "print(f\"  Classes: {list(test_generator.class_indices.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "## 2. Avaliar Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "evaluate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fazendo predi√ß√µes no conjunto de teste...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFazendo predi√ß√µes no conjunto de teste...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_generator\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m----> 5\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(test_generator, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_generator), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred_proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m y_true \u001b[38;5;241m=\u001b[39m test_generator\u001b[38;5;241m.\u001b[39mclasses\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Fazer predi√ß√µes\n",
    "print(\"Fazendo predi√ß√µes no conjunto de teste...\")\n",
    "test_generator.reset()\n",
    "\n",
    "y_pred_proba = model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# M√©tricas gerais\n",
    "test_generator.reset()\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"RESULTADOS NO CONJUNTO DE TESTE\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Loss: {test_loss:.4f}\")\n",
    "print(f\"Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classification-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relat√≥rio de classifica√ß√£o detalhado\n",
    "print(\"\\nRelat√≥rio de Classifica√ß√£o por Emo√ß√£o:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=emotion_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "## 3. Matriz de Confus√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matriz de confus√£o\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plotar\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=emotion_classes,\n",
    "    yticklabels=emotion_classes,\n",
    "    cbar_kws={'label': 'Quantidade'}\n",
    ")\n",
    "plt.title('Matriz de Confus√£o - Reconhecimento de Emo√ß√µes', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Emo√ß√£o Prevista', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Emo√ß√£o Real', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matriz normalizada (percentual)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    cm_normalized,\n",
    "    annot=True,\n",
    "    fmt='.2%',\n",
    "    cmap='YlOrRd',\n",
    "    xticklabels=emotion_classes,\n",
    "    yticklabels=emotion_classes,\n",
    "    cbar_kws={'label': 'Propor√ß√£o'}\n",
    ")\n",
    "plt.title('Matriz de Confus√£o Normalizada (%)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Emo√ß√£o Prevista', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Emo√ß√£o Real', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## 4. An√°lise de Erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "error-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar confus√µes mais comuns\n",
    "confusion_pairs = []\n",
    "\n",
    "for i in range(len(emotion_classes)):\n",
    "    for j in range(len(emotion_classes)):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            confusion_pairs.append({\n",
    "                'Real': emotion_classes[i],\n",
    "                'Previsto': emotion_classes[j],\n",
    "                'Quantidade': cm[i, j],\n",
    "                'Percentual': cm_normalized[i, j] * 100\n",
    "            })\n",
    "\n",
    "confusion_df = pd.DataFrame(confusion_pairs).sort_values('Quantidade', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Confus√µes Mais Comuns:\")\n",
    "print(\"=\"*60)\n",
    "display(confusion_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "misclassified",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar exemplos de erros\n",
    "def plot_misclassified_examples(n_examples=10):\n",
    "    \"\"\"Plota exemplos de imagens classificadas incorretamente\"\"\"\n",
    "    \n",
    "    # Encontrar √≠ndices de predi√ß√µes erradas\n",
    "    wrong_indices = np.where(y_pred != y_true)[0]\n",
    "    \n",
    "    if len(wrong_indices) == 0:\n",
    "        print(\"Nenhum erro encontrado!\")\n",
    "        return\n",
    "    \n",
    "    # Selecionar aleatoriamente alguns exemplos\n",
    "    sample_indices = np.random.choice(wrong_indices, size=min(n_examples, len(wrong_indices)), replace=False)\n",
    "    \n",
    "    # Obter imagens do generator\n",
    "    test_generator.reset()\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(len(test_generator)):\n",
    "        batch_images, batch_labels = test_generator[i]\n",
    "        images.extend(batch_images)\n",
    "        labels.extend(batch_labels)\n",
    "        if len(images) >= test_generator.samples:\n",
    "            break\n",
    "    \n",
    "    # Plotar\n",
    "    n_cols = 5\n",
    "    n_rows = (n_examples + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 4*n_rows))\n",
    "    axes = axes.flatten() if n_examples > 1 else [axes]\n",
    "    \n",
    "    fig.suptitle('Exemplos de Classifica√ß√µes Incorretas', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, ax in zip(sample_indices, axes):\n",
    "        img = images[idx].squeeze()\n",
    "        true_emotion = emotion_classes[y_true[idx]]\n",
    "        pred_emotion = emotion_classes[y_pred[idx]]\n",
    "        confidence = y_pred_proba[idx][y_pred[idx]] * 100\n",
    "        \n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(\n",
    "            f\"Real: {true_emotion}\\nPrevisto: {pred_emotion}\\nConf: {confidence:.1f}%\",\n",
    "            fontsize=10,\n",
    "            color='red'\n",
    "        )\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Esconder eixos extras\n",
    "    for ax in axes[len(sample_indices):]:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_misclassified_examples(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## 5. Curvas de Aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learning-curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar hist√≥rico (se dispon√≠vel)\n",
    "history_file = model_path.parent / model_path.name.replace('_best.h5', '_history.npz')\n",
    "\n",
    "if history_file.exists():\n",
    "    history_data = np.load(history_file)\n",
    "    \n",
    "    train_loss = history_data['train_loss']\n",
    "    train_acc = history_data['train_accuracy']\n",
    "    val_loss = history_data['val_loss']\n",
    "    val_acc = history_data['val_accuracy']\n",
    "    \n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    \n",
    "    # Plotar Loss e Accuracy\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    \n",
    "    # Loss\n",
    "    ax1.plot(epochs, train_loss, 'b-', label='Training Loss', linewidth=2)\n",
    "    ax1.plot(epochs, val_loss, 'r-', label='Validation Loss', linewidth=2)\n",
    "    ax1.set_title('Curva de Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Marcar melhor epoch\n",
    "    best_epoch = np.argmin(val_loss) + 1\n",
    "    ax1.axvline(best_epoch, color='green', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch})')\n",
    "    \n",
    "    # Accuracy\n",
    "    ax2.plot(epochs, train_acc, 'b-', label='Training Accuracy', linewidth=2)\n",
    "    ax2.plot(epochs, val_acc, 'r-', label='Validation Accuracy', linewidth=2)\n",
    "    ax2.set_title('Curva de Acur√°cia', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Marcar melhor epoch\n",
    "    best_epoch_acc = np.argmax(val_acc) + 1\n",
    "    ax2.axvline(best_epoch_acc, color='green', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch_acc})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    print(f\"\\nüìä Estat√≠sticas do Treinamento:\")\n",
    "    print(f\"  Melhor Validation Accuracy: {max(val_acc):.4f} (Epoch {np.argmax(val_acc) + 1})\")\n",
    "    print(f\"  Melhor Validation Loss: {min(val_loss):.4f} (Epoch {np.argmin(val_loss) + 1})\")\n",
    "    print(f\"  Total de Epochs: {len(epochs)}\")\n",
    "    print(f\"  Training Accuracy final: {train_acc[-1]:.4f}\")\n",
    "    print(f\"  Validation Accuracy final: {val_acc[-1]:.4f}\")\n",
    "else:\n",
    "    print(f\"‚ùå Arquivo de hist√≥rico n√£o encontrado: {history_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "## 6. An√°lise por Emo√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotion-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©tricas por emo√ß√£o\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Emo√ß√£o': emotion_classes,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support\n",
    "})\n",
    "\n",
    "print(\"\\nM√©tricas por Emo√ß√£o:\")\n",
    "display(metrics_df.sort_values('F1-Score', ascending=False))\n",
    "\n",
    "# Plotar\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(emotion_classes))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, precision, width, label='Precision', alpha=0.8)\n",
    "ax.bar(x, recall, width, label='Recall', alpha=0.8)\n",
    "ax.bar(x + width, f1, width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Emo√ß√£o', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('M√©tricas por Emo√ß√£o', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(emotion_classes, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
